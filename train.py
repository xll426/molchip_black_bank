"""Training script for CornerYOLO."""

import argparse
import csv
import math
import os
import random

import cv2
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader

from blackbank.dataset import TVCornerDataset, build_train_transform, build_val_transform
from blackbank.model import CornerYOLOOptimized
from blackbank.losses import detection_loss_new_center




def visualize_dataloader_samples(dataloader, save_dir='debug_vis', max_batches=1):
    """
    ä» dataloader ä¸­å–è‹¥å¹²ä¸ª batchï¼ˆé»˜è®¤ 1 ä¸ªï¼‰ï¼Œå¯¹æ¯å¼ å›¾ï¼ˆå·²è¢« letterbox ç¼©æ”¾åˆ°640Ã—640ï¼‰çš„
    æ£€æµ‹æ ‡æ³¨ï¼ˆå››è§’ç‚¹+æ–¹å‘ï¼‰åŠåˆ†å‰² mask è¿›è¡Œå¯è§†åŒ–ï¼Œå¹¶ä¿å­˜åˆ°æœ¬åœ°ã€‚

    æ•°æ®æ ¼å¼ï¼š
      images: (B, 3, 640, 640)
      targets: (B, 25)   # å‰24ç»´ä¸º 4 ä¸ªè§’ç‚¹ï¼ˆæ¯è§’6ç»´ï¼‰ï¼Œç¬¬25ç»´ä¸º obj_conf
      segs: (B, 1, 640, 640)  # åˆ†å‰² maskï¼Œå€¼åœ¨ 0ï½1ä¹‹é—´

    å¦‚æœ obj_conf > 0.5ï¼Œåˆ™åœ¨å›¾ä¸Šç”»ï¼š
      - 4ä¸ªè§’ç‚¹ï¼ˆè½¬æ¢æˆç»å¯¹åæ ‡ï¼‰
      - æŒ‰é¡ºæ—¶é’ˆé¡ºåºçš„å¤šè¾¹å½¢ï¼ˆ1->2->3->4->1ï¼‰
      - æ¯ä¸ªè§’ç‚¹å¯¹åº”çš„å‰å‘ã€åå‘å°çº¿æ®µï¼ˆè¡¨ç¤ºæ–¹å‘å‘é‡ï¼‰

    åŒæ—¶ï¼Œå°† seg mask è½¬æ¢ä¸ºä¼ªå½©è‰²çƒ­åŠ›å›¾ï¼Œå¹¶ä¸æ£€æµ‹æ ‡æ³¨å›¾è¿›è¡ŒåŠ æƒå åŠ ï¼Œæœ€åä¿å­˜ç»“æœã€‚
    """
    os.makedirs(save_dir, exist_ok=True)

    with torch.no_grad():
        for batch_idx, (images, targets, segs,flags) in enumerate(dataloader):
            # images: (B,3,640,640); targets: (B,25); segs: (B,1,640,640)
            batch_size = images.size(0)
            for i in range(batch_size):
                # 1. å°†å›¾åƒè½¬æ¢æˆ OpenCV BGR æ ¼å¼
                if flags[i]:
                    img_tensor = images[i]  # (3,640,640)
                    tgt = targets[i]        # (25,)
                    seg = segs[i]           # (1,640,640)
                    
                    img_np = img_tensor.permute(1, 2, 0).cpu().numpy()  # (640,640,3), RGB
                    img_np = (img_np * 255).astype(np.uint8)
                    img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

                    # 2. åˆ¤æ–­ obj_confï¼ˆæœ€å1ä¸ªæ•°ï¼‰
                    obj_conf = tgt[-1].item()
                    if obj_conf > 0.5:
                        # è§£æå‰24ç»´ï¼šæ¯è§’é¡ºåºï¼š [x, y, cos_forward, sin_forward, cos_backward, sin_backward]
                        corners_abs = []
                        lines_forward = []
                        lines_backward = []
                        for corner_idx in range(4):
                            base = corner_idx * 6
                            x_norm = tgt[base + 0].item()  # [0,1]
                            y_norm = tgt[base + 1].item()
                            cf = tgt[base + 2].item()  # cos forward
                            sf = tgt[base + 3].item()  # sin forward
                            cb = tgt[base + 4].item()  # cos backward
                            sb = tgt[base + 5].item()  # sin backward

                            # è½¬ä¸ºç»å¯¹åƒç´ åæ ‡ï¼ˆ640x640ï¼‰
                            x_abs = x_norm * 640
                            y_abs = y_norm * 640
                            corners_abs.append((x_abs, y_abs))

                            # å®šä¹‰ç»˜åˆ¶çº¿æ®µé•¿åº¦ï¼Œå¦‚30åƒç´ 
                            line_len = 30
                            xF = x_abs + cf * line_len
                            yF = y_abs + sf * line_len
                            xB = x_abs + cb * line_len
                            yB = y_abs + sb * line_len
                            lines_forward.append(((x_abs, y_abs), (xF, yF)))
                            lines_backward.append(((x_abs, y_abs), (xB, yB)))

                        # ç”»å¤šè¾¹å½¢è¾¹ç•Œ
                        poly_pts = np.array(corners_abs, dtype=np.int32).reshape((-1, 1, 2))
                        cv2.polylines(img_np, [poly_pts], isClosed=True, color=(0, 0, 255), thickness=2)
                        # ç»˜åˆ¶æ¯ä¸ªè§’ç‚¹
                        for (cx, cy) in corners_abs:
                            cv2.circle(img_np, (int(cx), int(cy)), radius=3, color=(0, 255, 0), thickness=-1)
                        # ç»˜åˆ¶å‰å‘å’Œåå‘å°çº¿æ®µ
                        for (p1, p2) in lines_forward:
                            cv2.line(img_np,
                                    (int(p1[0]), int(p1[1])),
                                    (int(p2[0]), int(p2[1])),
                                    (0, 255, 255), 2)  # é»„ç»¿è‰²
                        for (p1, p2) in lines_backward:
                            cv2.line(img_np,
                                    (int(p1[0]), int(p1[1])),
                                    (int(p2[0]), int(p2[1])),
                                    (255, 255, 0), 2)  # æµ…è“

                    # 3. åˆ†å‰² mask å¯è§†åŒ–ï¼šseg çš„å½¢çŠ¶ (1,640,640)ï¼Œå–ç¬¬ä¸€ä¸ªé€šé“
                    # è½¬æ¢ä¸º numpy, å½’ä¸€åŒ–åˆ° [0,255]ï¼Œå¹¶ç”¨ä¼ªå½©è‰²æ˜¾ç¤º
                    # seg_np = seg[0].detach().cpu().numpy()  # (640,640), å€¼åœ¨0~1
                    # seg_uint8 = np.clip(seg_np * 255, 0, 255).astype(np.uint8)
                    # seg_color = cv2.applyColorMap(seg_uint8, cv2.COLORMAP_JET)
                    
                    # # 4. å°†åˆ†å‰² heatmap å åŠ åˆ°æ£€æµ‹æ ‡æ³¨å›¾ä¸Šï¼ˆä¾‹å¦‚ 40%å åŠ ï¼‰
                    # alpha = 0.4
                    # overlay = cv2.addWeighted(img_np, 1.0, seg_color, alpha, 0)

                                    # 3. åˆ†å‰² mask å¯è§†åŒ–ï¼šseg çš„å½¢çŠ¶ (1,640,640)ï¼Œå–ç¬¬ä¸€ä¸ªé€šé“
                    seg_np = seg[0].detach().cpu().numpy()  # (640,640), å€¼åœ¨0~1ä¹‹é—´
                    # äºŒå€¼åŒ–: å¤§äºé˜ˆå€¼çš„ä½ç½®ä¸º True
                    threshold = 1
                    mask_bin = seg_np == threshold  # å¸ƒå°”æ•°ç»„

                    # ç”Ÿæˆä¸€ä¸ªä¸åŸå›¾åŒå°ºå¯¸çš„çº¯è‰² overlayï¼Œé¢œè‰²è®¾ä¸ºäº®çº¢è‰² (BGR: (0, 0, 255))
                    color_overlay = np.zeros_like(img_np, dtype=np.uint8)
                    # å°† mask ä¸º True çš„åƒç´ ç‚¹èµ‹äºˆäº®çº¢è‰²
                    color_overlay[mask_bin] = (0, 0, 255)

                    # å åŠ ï¼šåŸå›¾ä¸äº®çº¢ overlay æ··åˆï¼Œalpha å¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼ˆä¾‹å¦‚ 0.5ï¼‰
                    alpha = 0.5
                    overlay = cv2.addWeighted(img_np, 1.0, color_overlay, alpha, 0)

                    
                    # 5. ä¿å­˜ç»“æœï¼ˆæ–‡ä»¶åä¸­åŒæ—¶è®°å½• batch ä¸ç´¢å¼•ï¼‰
                    out_path = os.path.join(save_dir, f"batch{batch_idx}_idx{i}.jpg")
                    cv2.imwrite(out_path, overlay)
                    print(f"Saved visualization: {out_path}")
                    
            if batch_idx+1 >= max_batches:
                break










   

# ============ è®­ç»ƒ/éªŒè¯å¾ªç¯ ============


def collate_fn(batch):
    imgs, tgts, segs, flags = zip(*batch)
    return (torch.stack(imgs),
            torch.stack(tgts),
            torch.stack(segs),
            torch.tensor(flags))              # (B,)  bool / 0-1


def replace_silu_with_relu(module: nn.Module):
    """
    é€’å½’åœ°å°† module åŠå…¶å­æ¨¡å—ä¸­çš„ SiLU æ›¿æ¢ä¸º ReLU(inplace=True)ã€‚
    """
    for name, child in module.named_children():
        if isinstance(child, nn.SiLU):
            setattr(module, name, nn.ReLU(inplace=True))
        else:
            replace_silu_with_relu(child)



# è¯„ä¼°å‡½æ•°ï¼šæ£€æµ‹ä»»åŠ¡ï¼ˆä½¿ç”¨ detection_lossï¼‰
def evaluate_detection(model, loader, device='cpu'):
    model.eval()
    total_loss = 0.0
    count = 0
    with torch.no_grad():
        for imgs, tgts, segs, flags in loader:
            images = imgs.to(device)
            targets = tgts.to(device)
            _, det_out = model(images)
            loss, _, _ = detection_loss_new_center(det_out, targets, flags, device=device)
            total_loss += loss.item()
            count += 1
    return total_loss / (count + 1e-6)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--img_dir', default='/mnt/d/cv_molchip/black_bank/output/image', type=str)
    parser.add_argument('--label_dir', default='/mnt/d/cv_molchip/black_bank/output/label', type=str)
    parser.add_argument('--epochs', default=300, type=int)
    parser.add_argument('--batch_size', default=16, type=int)
    parser.add_argument('--lr', default=1e-4, type=float)
    parser.add_argument('--device', default='cuda', type=str)
    parser.add_argument('--img_w_size', default=640, type=int)
    parser.add_argument('--img_h_size', default=640, type=int)
    parser.add_argument('--resume', default='/mnt/d/cv_molchip/keypoint_detection_16/checkpoints/last_checkpoint.pth', type=str, help='path to resume checkpoint')
    parser.add_argument('--plot_path', default='loss_curve.png', type=str, help='path to save loss plot')
    args = parser.parse_args()

    device = args.device if torch.cuda.is_available() else 'cpu'
    print(f"Using device: {device}")

    # Prepare data loaders
    all_files = [f for f in os.listdir(args.img_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]
    random.shuffle(all_files)
    split_idx = int(0.8 * len(all_files))
    train_files = all_files[:split_idx]
    val_files = all_files[split_idx:]






    kernel_count = os.cpu_count()
    print(kernel_count)
    train_dataset = TVCornerDataset(img_dir=args.img_dir,label_dir=args.label_dir,file_list=train_files,img_w=args.img_w_size,img_h=args.img_h_size,transform=build_train_transform(args.img_w_size,args.img_h_size))
    val_dataset = TVCornerDataset(img_dir=args.img_dir,label_dir=args.label_dir,file_list=val_files,img_w=args.img_w_size,img_h=args.img_h_size,transform=build_val_transform(args.img_w_size,args.img_h_size))
  
    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=kernel_count, pin_memory=False, collate_fn=collate_fn)
    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, num_workers=kernel_count, pin_memory=False, collate_fn=collate_fn)
    # visualize_dataloader_samples(train_loader, save_dir='debug_vis', max_batches=1)
    # visualize_dataloader_samples(val_loader, save_dir='debug_vis', max_batches=1)
    # raise NotImplementedError


    # Create checkpoint directory
    os.makedirs('checkpoints', exist_ok=True)

    # Initialize model, optimizer, scheduler
    model = CornerYOLOOptimized().to(device)
    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr)   
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)

    start_epoch = 0
    best_det_loss = float('inf')

    # Resume from checkpoint if provided
    if args.resume and os.path.isfile(args.resume):
        print(f"Loading checkpoint '{args.resume}'")
        checkpoint = torch.load(args.resume, map_location=device)
        # model.load_state_dict(checkpoint['model_state_dict'])

        # missing, unexpected = model.load_state_dict(checkpoint['model_state_dict'],strict=False)                 # â† å…³é”®
        # print(f"âœ” loaded.  missing={len(missing)}, unexpected={len(unexpected)}")
        # åŠ è½½ checkpoint

        state_dict = checkpoint['model_state_dict']
        model_state = model.state_dict()

        # è¿‡æ»¤æ‰ shape ä¸ä¸€è‡´çš„å±‚
        filtered_dict = {k: v for k, v in state_dict.items() if k in model_state and v.shape == model_state[k].shape}
        print(f"âœ” filtered out {len(state_dict) - len(filtered_dict)} mismatched layers")

        # åŠ è½½åŒ¹é…çš„éƒ¨åˆ†
        model.load_state_dict(filtered_dict, strict=False)



        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        start_epoch = checkpoint['epoch'] + 1
        best_det_loss = checkpoint.get('best_det_loss', best_det_loss)
        print(f"Resuming from epoch {start_epoch}, best_det_loss={best_det_loss:.4f}")
  
    epochs_list = []
    train_losses = []
    val_losses = []

    import time  # åŠ åœ¨æ–‡ä»¶å¤´éƒ¨
    best_det_loss =7
    # Training loop
    for epoch in range(start_epoch, args.epochs):
        print(best_det_loss)
        start_time = time.time()  # ğŸ•’ å¼€å§‹æ—¶é—´
        

        model.train()
        total_loss = 0.0
        steps = 0

        for imgs, tgts, segs, flags in train_loader:
            # batch_start = time.time()  # ğŸ•’ æ¯ä¸ª batch å¼€å§‹
            imgs, tgts, flags = imgs.to(device), tgts.to(device), flags.to(device)
            _, preds = model(imgs)
            loss, cls_loss, reg_loss = detection_loss_new_center(preds, tgts, flags, device=device)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()
            steps += 1
            # batch_end = time.time()  # ğŸ•’ æ¯ä¸ª batch ç»“æŸ
            # print(f"  [Batch {steps}] Loss={loss.item():.4f} | Time={batch_end - batch_start:.2f}s")

        avg_loss = total_loss / max(steps, 1)
        scheduler.step()

        # Validation
        val_loss = evaluate_detection(model, val_loader, device=device)

        # ğŸ•’ ç»“æŸæ—¶é—´å¹¶æ‰“å°
        end_time = time.time()
        elapsed = end_time - start_time
        print(f"[Epoch {epoch+1}] TrainLoss={avg_loss:.4f} | ValLoss={val_loss:.4f} | LR={optimizer.param_groups[0]['lr']:.6f} | Time={elapsed:.2f}s")

        # Record for plotting
        epochs_list.append(epoch + 1)
        train_losses.append(avg_loss)
        val_losses.append(val_loss)

  

        # Save checkpoints
        ckpt = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict(),
            'best_det_loss': best_det_loss,
        }
        torch.save(ckpt, 'checkpoints/last_checkpoint.pth')
        print(val_loss)
        print(best_det_loss)
        # Save best
        if val_loss < best_det_loss:
            best_det_loss = val_loss
            torch.save(ckpt, 'checkpoints/best_checkpoint.pth')
            print("  ==> New best checkpoint saved!")

    print(f"Training complete. Best validation loss: {best_det_loss:.4f}")



    # Plot and save
    plt.figure()
    plt.plot(epochs_list, train_losses, label='Train Loss')
    plt.plot(epochs_list, val_losses, label='Val Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.savefig(args.plot_path)
    plt.close()


if __name__ == "__main__":
    main()

